#欠拟合
欠拟合是对现有的数据集学习得不够彻底\
###欠拟合的解决方法：
1，增加输入特征项\
2，增加网络参数(扩大网络规模，增加网络深度，提升模型表达力)\
3，减少正则化参数


#过拟合
对训练集学习得过好，模型缺乏泛化能力\
###过拟合的解决方法：
1，数据清洗，减少数据集中的噪声，使数据集更纯净\
2，增大训练集，让模型见到更多数据\
3，采用正则化\
4，增大正则化参数

#正则化缓解过拟合
正则化在损失函数中引入模型复杂度指标，
利用给w加权值，弱化了训练数据的噪声。
\
一般不正则化b\

loss = loss(y与y_)+ REGULARIZER * loss(w)\
模型中所有参数的损失函数
如:交叉嫡、均方误差\
给出参数w在总loss中的比例，即正则化的权重


用超参数REGULARIZER给出参数w在总loss中的比例，即正则化的权重。

###正则化的选择：
1,L1正则化大概率会使很多参数变为零，因此该方法可以通过稀疏参数，
即减少参数的数量，降低复杂度。\

2,L2正则化会使参数很接近0但不为0，
因为该方法可以通过减小参数值的大小降低复杂度。
